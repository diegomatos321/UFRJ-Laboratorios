{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 5 - Aprendizado de Máquina 2023.02\n",
    "Aluno: Diego Vasconcelos Schardosim de Matos - 120098723\n",
    "\n",
    "Esta tarefa épara ser reailizada com o dataset IRIS. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Separar 80% dos dados para treinamento e 20% para teste. Esse conjunto de teste será usado apenas no final de todo o trabalho. O conjunto de treino e teste deve ser balanceado (mesmo número de instâncias de cada classe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./iris.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['target']\n",
    "X = df.drop('target', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts().plot.pie(autopct='%3.1f%%', shadow=True, legend=True, startangle=45)\n",
    "plt.title('Distribuição do atributo de saída')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O dataset está bem distribuído"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Para os 80% restantes, você vai usar K-fold com K = 5, para várias arquiteturas da rede neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Inicialmente, utilize todas as variávéis de entrada do dataset.\n",
    "3. Utilize o classificador multi perceptron MLPClassifier com os seguintes valores:\n",
    "- função de ativação: ‘logistic’, ‘tanh’, ‘relu’\n",
    "- solver: ‘sgd’\n",
    "- os outros parâmetros devem ser os que são default.\n",
    "- o número de camadas e neurônios por camada ficam a seu critério\n",
    "4. Para cada fold:\n",
    "- informe o score de treinamento e teste\n",
    "- plote um gráfico com o comportamento da função de perda. Você pode plotar em um gráfico só, todas as funções de perda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes de treinar o Modelo, devo buscar por outliers e normalizar os dados \n",
    "\n",
    "X_train.plot(kind=\"box\", subplots=True, title=\"Outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao rodar o algoritmo acima algumas vezes, percebi que dependendo da seleção das instancias de teste pode haver ou não outliers na feature sepalWidthInCm.\n",
    "\n",
    "Como o dataset é pequeno, é possível que remover os outliers interfira na acurácia do treinamento, então irei testar o modelo com e sem os outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_my_model(model: MLPClassifier, axs = None, withOutliers=True) -> list:\n",
    "    acc_score = []\n",
    "\n",
    "    iteration = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        kf_x_train, kf_x_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "        kf_y_train, kf_y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        # Remover outliers\n",
    "        if withOutliers == False:\n",
    "            Q1 = kf_x_train['sepalWidthInCM'].quantile(0.25)\n",
    "            Q3 = kf_x_train['sepalWidthInCM'].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "\n",
    "            outliers = kf_x_train.loc[(kf_x_train['sepalWidthInCM'] < Q1 - 1.5 * IQR) | (kf_x_train['sepalWidthInCM'] > Q3 + 1.5 * IQR)]\n",
    "            kf_x_train = kf_x_train.drop(outliers.index)\n",
    "            kf_y_train = kf_y_train.drop(outliers.index)\n",
    "        \n",
    "        # Normalizar\n",
    "        # scaler = MinMaxScaler()\n",
    "        # columns = ['sepalLengthInCM', 'sepalWidthInCM', 'petalLengthInCM', 'petalWidthInCM']\n",
    "        # kf_x_train_normalized = kf_x_train.copy()\n",
    "        # kf_x_train_normalized[columns] = scaler.fit_transform(kf_x_train[columns])\n",
    "\n",
    "        # kf_x_test_normalized = kf_x_test.copy()\n",
    "        # kf_x_test_normalized[columns] = scaler.fit_transform(kf_x_test[columns])\n",
    "\n",
    "        model.fit(kf_x_train, kf_y_train)\n",
    "        acc = model.score(kf_x_test, kf_y_test)\n",
    "        acc_score.append(acc)\n",
    "\n",
    "        if axs is not None:\n",
    "            axs[iteration].plot(model.loss_curve_, label='Função de perda')\n",
    "            axs[iteration].set_title(f'KFold {iteration}')\n",
    "            iteration += 1\n",
    "    \n",
    "    return acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for activation_function in ['logistic', 'tanh', 'relu']:\n",
    "    print('=== Treinando com função de ativação: {} ==='.format(activation_function))\n",
    "\n",
    "    model = MLPClassifier(activation=activation_function, solver='sgd')\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=5, sharey=True)\n",
    "    acc_score = train_my_model(model, axs)\n",
    "    fig.suptitle(f\"Função de perda para {activation_function}\")\n",
    "\n",
    "    avg_acc_score = sum(acc_score) / 5\n",
    "\n",
    "    print('Resultados do treinamento')  \n",
    "    print('Accuracy of each fold: {}'.format(acc_score))\n",
    "    print('Avg accuracy: {}'.format(avg_acc_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for activation_function in ['logistic', 'tanh', 'relu']:\n",
    "    print('=== Treinando com função de ativação: {} ==='.format(activation_function))\n",
    "\n",
    "    model = MLPClassifier(activation=activation_function, solver='sgd')\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=5, sharey=True)\n",
    "    acc_score = train_my_model(model, axs, withOutliers=False)\n",
    "    fig.suptitle(f\"Função de perda para {activation_function}\")\n",
    "\n",
    "    avg_acc_score = sum(acc_score) / 5\n",
    "\n",
    "    print('Resultados do treinamento')  \n",
    "    print('Accuracy of each fold: {}'.format(acc_score))\n",
    "    print('Avg accuracy: {}'.format(avg_acc_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Analise o que ocorreu. \n",
    "\n",
    "Usando a técnica de reamostragem do K-Fold Cross Validation e o modelo de treinamento de Redes Neurais com funções de ativação igual a Logistica, Tanh ou Relu no aprendizado dos pesos de cada neuronio (backpropagation), o modelo não conseguiu convergir para uma solução dentro do limite máximo de 200 iterações.\n",
    "\n",
    "Também não houve diferença remnovendo ou mantendo os outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Ainda usando os 80% dos dados e K-fold=5, repita o experimento alterados os parâmetros anteriores. A escolha de qual(is) parâmetro(s) será(ão) alterados deve ser justificado. O que você espera alterando o(s) parâmetro(s)? O resultado obtido foi o esperado?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me vem em mente alterar quatro parametros:\n",
    "- Taxa de aprendizado: O valor da taxa de aprendizado padrão é muito baixo (0.001) fazendo com que demore para convergir, penso em deixa-lo 10x maior\n",
    "- Limite de iterações: Aumentar o limite máximo de iterações do modelo\n",
    "- Diminuir o numero de neuronios da rede para deixa-la mais simples. Pode ser que não precise de todos os 100 (valor padrão da biblioteca)\n",
    "- De acordo com a documentação da biblioteca, usar o método solver='lbfgs' converge melhor a para dataset pequenos. Como nosso caso possui apenas 150 instancias, estarei testando com ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for activation_function in ['logistic', 'tanh', 'relu']:\n",
    "    print('=== Treinando com função de ativação: {} ==='.format(activation_function))\n",
    "    \n",
    "    model = MLPClassifier(hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=1000, activation=activation_function, solver='lbfgs')\n",
    "\n",
    "    acc_score = train_my_model(model)\n",
    "\n",
    "    avg_acc_score = sum(acc_score) / 5\n",
    "\n",
    "    print('Resultados do treinamento')  \n",
    "    print('Accuracy of each fold: {}'.format(acc_score))\n",
    "    print('Avg accuracy: {}'.format(avg_acc_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for activation_function in ['logistic', 'tanh', 'relu']:\n",
    "    print('=== Treinando com função de ativação: {} ==='.format(activation_function))\n",
    "    \n",
    "    model = MLPClassifier(hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=1000, activation=activation_function, solver='lbfgs')\n",
    "\n",
    "    acc_score = train_my_model(model, withOutliers=False)\n",
    "\n",
    "    avg_acc_score = sum(acc_score) / 5\n",
    "\n",
    "    print('Resultados do treinamento')  \n",
    "    print('Accuracy of each fold: {}'.format(acc_score))\n",
    "    print('Avg accuracy: {}'.format(avg_acc_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como esperado, alterando os parametros mencionados conseguimos uma convergencia rápida e uma boa acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7- Após terminar todos os experientos, escolha o modelo gerado que você considera o melhor resultado. Usando os parâmetros deste modelo, faça um novo treinamento usando todos os 80% dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=(10,), learning_rate_init=0.01, max_iter=1000, activation='tanh', solver='lbfgs')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8- Avalie o modelo gerado no item 8 usando as 15 instâncias que não foram usadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_values = model.predict(X_test)\n",
    "acc = accuracy_score(pred_values, y_test)\n",
    "\n",
    "print('Resultados do treinamento')\n",
    "print('Acurácia: {}'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
